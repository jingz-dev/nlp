{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90447/2965437891.py:1: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  device = torch.device('cuda') if torch.has_cuda else torch.device('cpu')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.has_cuda else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txn = torchvision.transforms.ToTensor()\n",
    "train_dataset = torchvision.datasets.MNIST('./data', train=True, transform=txn)\n",
    "test_dataset = torchvision.datasets.MNIST('./data', train=False, transform=txn)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torchvision.transforms.Normalize() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgClassification(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImgClassification, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 1, 3) # 28 x 28 -> 26 x 26\n",
    "        self.conv2 = torch.nn.Conv2d(1, 1, 3) # 26 x 26 -> 24 x 24 \n",
    "        self.pool = torch.nn.MaxPool2d(2) # 12 x 12\n",
    "        self.fc1 = torch.nn.Linear(144, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImgClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1056, 0.1049, 0.0979, 0.0914, 0.1120, 0.1035, 0.0893, 0.0970, 0.0914,\n",
       "         0.1069]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -0.09918611496686935\n",
      "loss: -0.10149599611759186\n",
      "loss: -0.10158921033143997\n",
      "loss: -0.10971064120531082\n",
      "loss: -0.13682223856449127\n",
      "loss: -0.18449285626411438\n",
      "loss: -0.35349100828170776\n",
      "loss: -0.44351667165756226\n",
      "loss: -0.455499529838562\n",
      "loss: -0.5711482167243958\n",
      "loss: -0.6180008053779602\n",
      "loss: -0.623308539390564\n",
      "loss: -0.6921536922454834\n",
      "loss: -0.7243461012840271\n",
      "loss: -0.7844183444976807\n",
      "loss: -0.7786763310432434\n",
      "loss: -0.7214035987854004\n",
      "loss: -0.7776294946670532\n",
      "loss: -0.7498915195465088\n",
      "loss: -0.7745018601417542\n",
      "loss: -0.7957522869110107\n",
      "loss: -0.9126114249229431\n",
      "loss: -0.8246760368347168\n",
      "loss: -0.6849827766418457\n",
      "loss: -0.8836206197738647\n",
      "loss: -0.7940009832382202\n",
      "loss: -0.8136528730392456\n",
      "loss: -0.8724168539047241\n",
      "loss: -0.8783845901489258\n",
      "loss: -0.881289541721344\n",
      "loss: -0.8637606501579285\n",
      "loss: -0.8897256851196289\n",
      "loss: -0.8742358684539795\n",
      "loss: -0.876427412033081\n",
      "loss: -0.9771164655685425\n",
      "loss: -0.8286897540092468\n",
      "loss: -0.7829371094703674\n",
      "loss: -0.8229775428771973\n",
      "loss: -0.8616637587547302\n",
      "loss: -0.8302369713783264\n",
      "loss: -0.8402098417282104\n",
      "loss: -0.8818498253822327\n",
      "loss: -0.857241153717041\n",
      "loss: -0.9295759797096252\n",
      "loss: -0.8527695536613464\n",
      "loss: -0.9032257795333862\n",
      "loss: -0.8499175310134888\n",
      "loss: -0.8452045321464539\n",
      "loss: -0.8511642813682556\n",
      "loss: -0.8555083274841309\n",
      "loss: -0.8608018755912781\n",
      "loss: -0.8946524262428284\n",
      "loss: -0.8798376321792603\n",
      "loss: -0.9390037655830383\n",
      "loss: -0.8887261748313904\n",
      "loss: -0.888078510761261\n",
      "loss: -0.8875390887260437\n",
      "loss: -0.9092459082603455\n",
      "loss: -0.8615448474884033\n",
      "loss: -0.9141932725906372\n",
      "loss: -0.8740181922912598\n",
      "loss: -0.9750983715057373\n",
      "loss: -0.9469830989837646\n",
      "loss: -0.9336674809455872\n",
      "loss: -0.8805913925170898\n",
      "loss: -0.8814916610717773\n",
      "loss: -0.837394654750824\n",
      "loss: -0.8112297058105469\n",
      "loss: -0.9079973697662354\n",
      "loss: -0.9176985025405884\n",
      "loss: -0.8250821232795715\n",
      "loss: -0.7658499479293823\n",
      "loss: -0.8881704807281494\n",
      "loss: -0.8508872985839844\n",
      "loss: -0.8588632345199585\n",
      "loss: -0.9132785797119141\n",
      "loss: -0.9065415859222412\n",
      "loss: -0.8944045305252075\n",
      "loss: -0.891045331954956\n",
      "loss: -0.8455289006233215\n",
      "loss: -0.8488373756408691\n",
      "loss: -0.8954839110374451\n",
      "loss: -0.9418022036552429\n",
      "loss: -0.8937894105911255\n",
      "loss: -0.9578773975372314\n",
      "loss: -0.9028734564781189\n",
      "loss: -0.8914694786071777\n",
      "loss: -0.9013587832450867\n",
      "loss: -0.8871269226074219\n",
      "loss: -0.936953067779541\n",
      "loss: -0.8674665689468384\n",
      "loss: -0.9705303907394409\n",
      "loss: -0.9841963648796082\n",
      "loss: -0.9939042329788208\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "model.to(device)\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch_idx % 10 == 0:\n",
    "        print(f'loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9022\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "print(f'acc: {correct / len(test_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (sample_data, sample_target) = next(enumerate(train_loader))\n",
    "sample_data = sample_data.to(device)\n",
    "sample_target = sample_target.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.6246, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.nll_loss(model(sample_data[0]), sample_target[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_target[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
